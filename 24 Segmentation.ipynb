{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'E:\\01 TLS\\03 CODEX analysis\\07 mask generation\\ark-analysis-main\\src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import xarray as xr\n",
    "from alpineer import io_utils\n",
    "\n",
    "from ark.segmentation import marker_quantification, segmentation_utils\n",
    "from ark.utils import (deepcell_service_utils, example_dataset,\n",
    "                       plot_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set up the base directory\n",
    "base_dir = r\"\"\n",
    "# set up file paths\n",
    "file_path = r''\n",
    "#file_name = '12-D3'\n",
    "#result_path = os.path.join(file_path, file_name)\n",
    "result_path = file_path\n",
    "\n",
    "cell_table_dir = os.path.join(result_path, \"cell_table\")\n",
    "deepcell_input_dir = os.path.join(result_path, \"deepcell_input\")\n",
    "deepcell_output_dir = os.path.join(result_path, \"deepcell_output\")\n",
    "deepcell_visualization_dir = os.path.join(result_path, \"deepcell_visualization\")\n",
    "\n",
    "# create directories if do not exist\n",
    "for directory in [cell_table_dir, deepcell_input_dir, deepcell_output_dir, deepcell_visualization_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "# input data file path\n",
    "tiff_dir = base_dir\n",
    "fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# Due to the file 初始思路 from QQ, we decide nuclear and membrane channel\n",
    "# nuclear channel name(s) (or nucs = None)\n",
    "nucs = ['DAPI']\n",
    "# membrane channel name(s) (or mems = None)\n",
    "mems = ['CD45','CD20','CD3e','CD68','CD66b','CD31']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tiffs in 2 batches...\n",
      "Segmentation progress for batch_1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11d483210624f10b803e86b45e3a488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation progress for batch_2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3965c17e25964ee0b5e8e49659e69799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data from P_1\n",
      "extracting data from P_2\n",
      "extracting data from P_3\n",
      "extracting data from P_4\n",
      "extracting data from P_5\n",
      "extracting data from P_6\n",
      "extracting data from T_1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate and save deepcell input tiffs\n",
    "# set img_sub_folder param to None if the image files in tiff_dir are not in a separate sub folder \n",
    "deepcell_service_utils.generate_deepcell_input(\n",
    "    deepcell_input_dir,\n",
    "    tiff_dir,\n",
    "    nucs,\n",
    "    mems,\n",
    "    fovs,\n",
    "    img_sub_folder=None\n",
    ")\n",
    "\n",
    "# Mesmer was trained on data acquired at 20X resolution. \n",
    "#If your image data was acquired at a different resolution,\n",
    "# you will get the best performance by rescaling. \n",
    "#The rescale factor will increase or decrease the image resolution by the value you provide.\n",
    "# For example, if you data was acquired at 10X, use a `rescale_factor` of 2.\n",
    "# If your data was acquired at 60X resolution, use a `rescale_factor` of 0.33.\n",
    "\n",
    "rescale_factor = 1.0\n",
    "deepcell_service_utils.create_deepcell_output(deepcell_input_dir, \n",
    "                                              deepcell_output_dir, \n",
    "                                              fovs=fovs, \n",
    "                                              scale=rescale_factor)\n",
    "\n",
    "# save the overlaid segmentation labels for each fov (these will not display, but will save in viz_dir)\n",
    "segmentation_utils.save_segmentation_labels(\n",
    "    segmentation_dir=deepcell_output_dir,\n",
    "    data_dir=deepcell_input_dir,\n",
    "    output_dir=deepcell_visualization_dir,\n",
    "    fovs=io_utils.remove_file_extensions(fovs),\n",
    "    channels=['nuclear_channel', 'membrane_channel']\n",
    ")\n",
    "\n",
    "# set to True to add nuclear cell properties to the expression matrix\n",
    "nuclear_counts = False\n",
    "\n",
    "# set to True to bypass expensive cell property calculations\n",
    "# only cell label, size, and centroid will be extracted if True\n",
    "fast_extraction = False\n",
    "\n",
    "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
    "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
    "# with each fov given its own folder and all fovs having the same channels\n",
    "#The bactch size means run rov numbers simutaneously\n",
    "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
    "    marker_quantification.generate_cell_table(segmentation_dir=deepcell_output_dir,\n",
    "                                              tiff_dir=tiff_dir,\n",
    "                                              img_sub_folder=None,\n",
    "                                              fovs=fovs,\n",
    "                                              batch_size=10,\n",
    "                                              nuclear_counts=nuclear_counts,\n",
    "                                              fast_extraction=fast_extraction)\n",
    "\n",
    "\n",
    "compression = None\n",
    "cell_table_size_normalized.to_csv(os.path.join(cell_table_dir, 'cell_table_size_normalized.csv'),\n",
    "                                  compression=compression, index=False)\n",
    "cell_table_arcsinh_transformed.to_csv(os.path.join(cell_table_dir, 'cell_table_arcsinh_transformed.csv'),\n",
    "                                      compression=compression, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
